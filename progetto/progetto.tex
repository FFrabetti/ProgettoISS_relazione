\documentclass{../llncs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% package sillabazione italiana e uso lettere accentate
% \usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% per gli elenchi
\usepackage{enumitem}

% https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{listings}

\usepackage{xcolor}
\definecolor{darkgreen}{HTML}{007700}

\lstset{
	basicstyle=\small\ttfamily,
	columns=fullflexible,
	keywordstyle=\color{violet}\bfseries,
	commentstyle=\color{darkgreen},
	breaklines=true,	 			% sets automatic line breaking
	captionpos=b,					% sets the caption-position to bottom
	stringstyle=\color{blue},     	% string literal style
	showstringspaces=false, 		% no special string spaces
	caption={\lstname},
	% title=\lstname,               % show the filename of files included with \lstinputlisting;
	numbers=left,
	numberstyle=\tiny,
	stepnumber=1,
	numbersep=5pt,
	frame=shadowbox
	% , float=*
}

\lstdefinestyle{style_qa}{
	language=C++,
	morekeywords={
		Plan,System,Event,Dispatch,Context,ip,host,port,-httpserver,QActor,context,
		normal,switchTo,transition,whenMsg,finally,repeatPlan,stopAfter,resumeLastPlan,
		onMsg,addRule,replyToCaller,onEvent,removeRule,javaRun,whenTime,sendto,emit,else,not,
		selfMsg,forward,delay,whenEvent,printCurrentEvent
	}
}

\lstnewenvironment{qacode}[1][]{\lstset{style=style_qa, #1}}{}
% \begin{qacode}[caption={Programma Blink, "Hello World!"}]
% ...
% \end{qacode}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{url}
\usepackage{xspace}
\usepackage{color}
\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{../manifest}

\makeatother

% https://en.wikibooks.org/wiki/LaTeX/Hyperlinks
% LaTeXimpaziente: "Il pacchetto hyperref, che di regola va caricato per ultimo, crea i collegamenti ipertestualivall’interno del documento, rendendo cliccabili i riferimenti incrociati"
\usepackage{hyperref}

%%%%%%%
 \newif\ifpdf
 \ifx\pdfoutput\undefined
 \pdffalse % we are not running PDFLaTeX
 \else
 \pdfoutput=1 % we are running PDFLaTeX
 \pdftrue
 \fi
%%%%%%%
 \ifpdf
 \usepackage[pdftex]{graphicx}
 \else
 \usepackage{graphicx}
 \fi
%%%%%%%%%%%%%%%
 \ifpdf
 \DeclareGraphicsExtensions{.pdf, .jpg, .tif}
 \else
 \DeclareGraphicsExtensions{.eps, .jpg}
 \fi
%%%%%%%%%%%%%%%

\newcommand{\java}{\textsf{Java}}
\newcommand{\android}{\texttt{Android}}
\newcommand{\dsl}{\texttt{DSL}}
\newcommand{\jazz}{\texttt{Jazz}}
\newcommand{\rtc}{\texttt{RTC}}
\newcommand{\ide}{\texttt{Contact-ide}}
\newcommand{\xtext}{\texttt{XText}}
\newcommand{\xpand}{\texttt{Xpand}}
\newcommand{\xtend}{\texttt{Xtend}}
\newcommand{\pojo}{\texttt{POJO}}
\newcommand{\junit}{\texttt{JUnit}}

\newcommand{\action}[1]{\texttt{#1}\xspace}
% \newcommand{\codescript}[1]{{\scriptsize{\texttt{#1}}}\xspace}
\newcommand{\codescript}[1]{{\mbox{\small{\texttt{#1}}}}\xspace}
\newcommand{\code}[1]{{\color{blue}\small{\texttt{#1}}}}
\newcommand{\fname}[1]{{\small{\color{magenta}\texttt{#1}}}}
\newcommand{\node}{\textsf{NodeJs}}
\newcommand{\qa}{\textsf{\textit{QActor}}}

% Cross-referencing
\newcommand{\labelsec}[1]{\label{sec:#1}}
\newcommand{\xs}[1]{\sectionname~\ref{sec:#1}}
\newcommand{\xsp}[1]{\sectionname~\ref{sec:#1} \onpagename~\pageref{sec:#1}}
\newcommand{\labelssec}[1]{\label{ssec:#1}}
\newcommand{\xss}[1]{\subsectionname~\ref{ssec:#1}}
\newcommand{\xssp}[1]{\subsectionname~\ref{ssec:#1} \onpagename~\pageref{ssec:#1}}
\newcommand{\labelsssec}[1]{\label{sssec:#1}}
\newcommand{\xsss}[1]{\subsectionname~\ref{sssec:#1}}
\newcommand{\xsssp}[1]{\subsectionname~\ref{sssec:#1} \onpagename~\pageref{sssec:#1}}
\newcommand{\labelfig}[1]{\label{fig:#1}}
\newcommand{\xf}[1]{\figurename~\ref{fig:#1}}
\newcommand{\xfp}[1]{\figurename~\ref{fig:#1} \onpagename~\pageref{fig:#1}}
\newcommand{\labeltab}[1]{\label{tab:#1}}
\newcommand{\xt}[1]{\tablename~\ref{tab:#1}}
\newcommand{\xtp}[1]{\tablename~\ref{tab:#1} \onpagename~\pageref{tab:#1}}
% Category Names
\newcommand{\sectionname}{Section}
\newcommand{\subsectionname}{Subsection}
\newcommand{\sectionsname}{Sections}
\newcommand{\subsectionsname}{Subsections}
\newcommand{\secname}{\sectionname}
\newcommand{\ssecname}{\subsectionname}
\newcommand{\secsname}{\sectionsname}
\newcommand{\ssecsname}{\subsectionsname}
\newcommand{\onpagename}{on page}

\newcommand{\xauthA}{Filippo Frabetti}
\newcommand{\xauthB}{Nicola Semprini}
\newcommand{\xauthC}{Paolo Magnani}
\newcommand{\xfaculty}{II Faculty of Engineering}
\newcommand{\xunibo}{Alma Mater Studiorum -- University of Bologna}
\newcommand{\xaddrBO}{viale Risorgimento 2}
\newcommand{\xaddrCE}{via Venezia 52}
\newcommand{\xcityBO}{40136 Bologna, Italy}
\newcommand{\xcityCE}{47023 Cesena, Italy}

%
% Comments
%
% What’s wrong with \bf, \it, etc.? --> https://texfaq.org/FAQ-2letterfontcmd
% \newcommand{\todo}[1]{\bf{TODO:}\emph{#1}}
\newcommand{\todo}[1]{\textbf{TODO:} \emph{#1}}

\begin{document}

\title{Software Systems Engineering: Final task 2018}

\author{\xauthA, \xauthB, \xauthC}

\institute{%
  \xunibo\\\xaddrBO, \xcityBO\\
  \email{filippo.frabetti@studio.unibo.it}\\
  \email{nicola.semprini4@studio.unibo.it}\\
  \email{paolo.magnani5@studio.unibo.it}
}

\maketitle

% %%%%%%%%%%%%%%%%%%%%%%%% ABSTRACT + KEYWORDS - TODO... %%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\footnotesize

This document is the explicit representation of the production process adopted.\\

\todo{abstract and keywords}

% (This part is optional)
%%This a Latex template to be used for the explicit representation of the production process adopted in the Software Systems Engineering course. 
% THIS DOCUMENT MUST FILL AT MOST TWO PAGES AND MUST BE PRINTED ON A SINGLE PAPER SHEET.

% The document can be compiled by using the \fname{kitISLatex.zip} given in \code{iss2018/it.unibo.issMaterial/issdocs/Lab}
  
\keywords{
% (This part is optional)
Software engineering, software development process, process representation, ...
}
\end{abstract}

% evita le righe eccessivamente lunghe aumentando la spaziatura tra le parole
% Il comando \fussy ripristina le impostazioni predefinite 
\sloppy

%===========================================================================
\section{Introduction}
\labelsec{intro}
%===========================================================================

%===========================================================================
\section{Vision}
\labelsec{vision}

Scegliamo di procedere top-down, con zooming progressivo verso i dettagli.
%=========================================================================== 

%===========================================================================
\section{Requirements}
\labelsec{Requirements}

%With reference to a \texttt{mbot} physical robot working in a virtual environment, build an application that sends the data sensed by the virtual and the real sonars to the radar. More specifically:
%\begin{itemize}
%\item[-]the data of the \emph{virtual sonar} \texttt{sonar1} must be displayed on the direction of angle=\fname{30};
%\item[-]the data of the \emph{virtual sonar} \texttt{sonar2} must be displayed on the direction of angle=\fname{120};
%\item[-]the data of the \emph{virtual sonar} on the virtual robot must be displayed on the direction of angle=\fname{90} at the fixed distance of \fname{40};
%\item[-]the data of the \emph{real sonar} on the physical robot must be displayed on the direction of angle=\fname{0};
%\end{itemize}

% 13 - A new problem
%\begin{enumerate}
%\item The physical robot must expose in a visible way a \code{Led} and:
%\begin{itemize}
%\item[-] the Led must be \code{on} when the robot is engaged by an user (human or machine);
%\item[-] the Led must be \code{off} when the robot is available for booking.
%\end{itemize}
%\item the robot system does not expose any public available usage interface;
%\item in order to use the robot, an user must first of all send 'to the system' a \code{booking request}. The system
%must return an answer including an \code{access token} if the robot is available. If the answer is negative, (robot
%already engaged) and the request includes a '\texttt{notify-me flag}', the system must notify the user when to robot
%becomes again available;
%\item the user that receives the \code{access token} must send within a given \code{acquisition-deadline} (e.g. \code{30 sec}) the request for a \emph{robot-driving command interface}, by appending to the request the \code{access token}. If the
%\emph{acquisition-deadline} expires, the robot returns in its 'available state';
%\item the user can use the \emph{robot-driving command interface} at most for a prefixed \code{usage-duration} time;
%\item the user can explicitly release the robot resource by sending a \code{booking release} message;
%\item if many users attempt to book the robot resource 'at the same time', the system could operate in two different
%ways:
%\begin{itemize}
%\item[(a)] by selecting the first \emph{emitted} request;
%\item[(b)] by selecting the first \emph{received} request
%\end{itemize}
%\end{enumerate}

% FINAL TASK 2018
In a home of a given city (e.g. Bologna), a \texttt{ddr} robot is used to clean the floor of a room (\code{R-FloorClean}).

The floor in the room is a flat floor of solid material and is equipped with two \emph{sonars}, named \code{sonar1} and \code{sonar2} as shown in the picture (\code{sonar1} is that at the top). The initial position (\code{start-point}) of the robot is detected by \code{sonar1}, while the final position (\code{end-point}) is detected by \code{sonar2}.\\

\noindent The robot works under the following conditions:
\begin{enumerate}
\item \code{R-Start}: an \code{authorized user} has sent a \texttt{START} command by using a human \texttt{GUI} interface (\code{console}) running
on a conventional PC or on a smart device (\texttt{Android}).
\item \code{R-TempOk}: the value temperature of the city is not higher than a prefixed value (e.g. \texttt{25} degrees Celsius).
\item \code{R-TimeOk}: the current clock time is within a given interval (e.g. between \texttt{7} a.m and \texttt{10} a.m).
\end{enumerate}

\noindent While the robot is working:
\begin{itemize}[label={--}]
\item it must blink a \texttt{Led} put on it, if the robot is a \fname{real} robot (\code{R-BlinkLed}).
\item it must blink a \texttt{Led Hue Lamp} available in the house, if the robot is a \fname{virtual} robot (\code{R-BlinkHue}).
\item it must avoid fixed obstacles (e.g. furniture) present in the room (\code{R-AvoidFix}) and/or mobile obstacles like
balls, cats, etc. (\code{R-AvoidMobile}).
\end{itemize}

Moreover, the robot must stop its activity when one of the following conditions apply:
\begin{enumerate}
\item \code{R-Stop}: an \code{authorized user} has sent a \texttt{STOP} command by using the \code{console}.
\item \code{R-TempKo}: the value temperature of the city becomes higher than the prefixed value.
\item \code{R-TimeKo}: the current clock time is beyond the given interval.
\item \code{R-Obstacle}: the robot has found an obstacle that it is unable to avoid.
\item \code{R-End}: the robot has finished its work.
\end{enumerate}

%During its work, the robot can optionally:
%\begin{itemize}[label={--}]
%\item \code{R-Map}: build a map of the room floor with the position of the fixed obstacles. Once built, this map can be
%used to define a plan for an (optimal) path form the \code{start-point} to the \code{end-point}.
%\end{itemize}
%
%Other requirements:
%\begin{enumerate}
%\item The work can be done by a team composed of \code{NT} people, with \code{1<=NT<=4}.
%\item If \code{NT>1}, the team must explicitly indicate the work done by each component.
%\item If \code{NT==4}, the requirement \code{R-Map} is mandatory.
%\end{enumerate}
%===========================================================================

%===========================================================================
\section{Requirement analysis}
\labelsec{ReqAnalysis}

Dai requisiti si delineano 5 entità:
\begin{enumerate}
\item il robot, che può essere sia fisico sia virtuale (\texttt{RealDDR} e \texttt{VirtualDDR}), e l'ambiente in cui si muove (fisico/virtuale)
\item gli attuatori: il \texttt{Led} per il robot reale e l'\texttt{Hue Lamp} per quello virtuale
\item i sensori remoti: un indicatore di temperatura (\texttt{TemperatureSensor}) e un orologio (\texttt{Clock})
\item un utilizzatore umano (\texttt{HumanOperator})
\item più un componente che andrà ad incapsulare l'\texttt{Application logic}
\end{enumerate}

\noindent L'ambiente è inoltre costituito a sua volta da:
\begin{itemize}[label={--}]
\item 2 sensori \code{sonar1} e \code{sonar2} (ambiente virtuale)
\item ostacoli fissi (pareti) e mobili
\end{itemize}

L'architettura del sistema può essere descritta in maniera informale dalla \xf{informalRA}.
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.4]{img/informalReqAnalysis.png}
\caption{Architettura informale ottenuta dall'analisi dei requisiti}\labelfig{informalRA}
\end{figure}

\subsection{Actuators}
Il \texttt{Led}, essendo un componente estremamente semplice e trovandosi sul robot fisico, può essere visto come un'entità passiva senza un proprio flusso di controllo. Pertanto il modello del \texttt{Led} -- un oggetto Java -- può essere formalmente definito dalla seguente interfaccia:

\begin{center}
\includegraphics[scale=0.4]{img/iled.png}
\end{center}

L'interazione con il \texttt{Led} può quindi avvenire tramite \textit{procedure call} ad opera del robot fisico su cui si trova.\\

L'\texttt{Hue Lamp} è invece un'entità attiva che ci viene fornita dal committente insieme ad un componente software per poter interagire con essa attraverso un'interfaccia \textit{RESTful}
\footnote{\url{https://www.developers.meethue.com/philips-hue-api}}.

Possiamo quindi definire il modello di un attore in grado di interagire con l'\texttt{Hue Lamp}. Per farlo usiamo il linguaggio custom della nostra Software House \qa, poiché ci permette di modellare sistemi distribuiti eterogenei.\\

\lstinputlisting[style=style_qa]{../it.unibo.finalTask2018/src/hueLampAgent.qa}

Si noti come la scelta di utilizzare l'evento \codescript{blinkCmd} consente di far \textit{lampeggiare} più dispositivi senza che questi siano noti a priori dalla sorgente che emette tali eventi in base alla logica applicativa.

\subsection{Sensors}
Poiché abbiamo a che fare con sensori remoti, ci viene naturale modellarli come attori che rendono disponibili delle informazioni espresse in un certo formato.\\
Nello specifico, sono possibili tre approcci:
\begin{itemize}
\item \textbf{polling:} chi necessita dell'informazione a farsi carico di fare richiesta periodicamente al sensore;
\item \textbf{pattern observer:} l'observer si registra presso l'observable e viene notificato al cambiamento di stato di quest'ultimo;
\item \textbf{publish/subscribe:} è il sensore stesso a pubblicare all'esterno le informazioni quando queste sono disponibili ad uso degli eventuali subscriber.
\end{itemize}
Scegliamo di adottare la seconda strategia, poiché meno costosa in termini di dati scambiati e poiché garantisce un minor accoppiamento tra le entità coinvolte.

Anche in questo caso il sensore, non conoscendo i componenti interessati, emette un evento che può essere percepito da chiunque sia in ascolto.\\

\lstinputlisting[style=style_qa]{../it.unibo.finalTask2018/src/temperatureAgent.qa}

\noindent Si riportano solo le variazioni essenziali per il \texttt{Clock}:

\lstinputlisting[style=style_qa, firstline=14, lastline=21, firstnumber=14]{../it.unibo.finalTask2018/src/clockAgent.qa}

\subsection{Robot}
Ci viene fornito un modello del robot espresso nel linguaggio \qa
\footnote{it.unibo.mbot.divide/src/realRobotExecutor.qa}: questi è in grado di ricevere messaggi \codescript{moveRobot : moveRobot( CMD )} e di interpretarli come comandi di movimento (stop, forward, left, right, backward).

Il robot è anche dotato di un sonar frontale che gli permette di rilevare la presenza di ostacoli (\code{R-AvoidFix} e \code{R-AvoidMobile}). Il robot riveste quindi il duplice ruolo di attuatore e di sensore, in quanto emette informazioni relative alla distanza dagli ostacoli che incontra sotto forma di eventi \codescript{frontSonar : sonar( DISTANCE )}.\\

Il robot è quindi un'entità attiva il cui scopo è interpretare i messaggi ricevuti in un certo formato ed emettere eventi relativi al sonar frontale. L'implementazione delle varie mosse è delegata ad un'opportuna classe Java che può essere modificata senza alterare il modello del robot.\\

\lstinputlisting[style=style_qa]{../it.unibo.finalTask2018/src/robotDDR.qa}

\vspace{8px}

Nell'ambiente virtuale sono presenti due sonar in grado di rilevare la presenza di un robot che passi in corrispondenza di uno dei due. Per questo motivo definiamo un ulteriore evento \codescript{sonarSensor : sonar(NAME, DISTANCE)}, dove \codescript{NAME} è \code{sonar1} o \code{sonar2}.\\

Da notare come l'emissione di tali eventi dipenda dalla specifica implementazione del \textit{virtual environment} (le operazioni ad esso relative sono delegate ad una classe Java):

\lstinputlisting[language=Java, firstline=7, lastline=17, firstnumber=7]{../it.unibo.finalTask2018/src/it/unibo/finalTask2018/adapter/envAdapter.java}

\subsection{HumanOperator}
Lo \texttt{HumanOperator} può essere modellato come un emettitore di comandi per il robot. Per disaccoppiare le comunicazioni tra sorgente e destinatario dei comandi, l'operator si rivolge ad una terza entità che rappresenta la logica applicativa, così da non essere vincolato a conoscere l'identità di ogni possibile robot pilotabile.\\

\lstinputlisting[style=style_qa]{../it.unibo.finalTask2018/src/humanOperator.qa}

Per un primo testing, l'intermediario dei messaggi è l'attore \codescript{testapplqa} che si trova nello stesso contesto dell'operator. In futuro, quest'ultimo dovrà conoscere il contesto dell'entità che rappresenta la logica applicativa, così da poterle inviare messaggi (vedi riga 6).

\subsection{Application logic}
La nostra applicazione, oltre ad incapsulare le politiche della logica applicativa, deve innanzitutto agire come \textit{``system integrator''}, mettendo in collegamento i vari componenti così che questi possano interagire.
Si noti infatti come ogni componente è stato fino ad ora modellato come un micro-servizio indipendente.\\

L'immagine della \xf{informalRA} può essere quindi formalmente definita dal seguente sistema {\qa}:\\

\lstinputlisting[style=style_qa]{../it.unibo.finalTask2018/src/reqAnalysisModel.qa}

In questo caso sensori, attuatori, operatori e robot sono stati tutti inseriti all'interno di un unico contesto per motivi di rapidità di modellazione e di \textit{integration testing}.

\vspace{8px}

Poiché abbiamo utilizzato un modello eseguibile, questo ci fornisce anche un primo prototipo funzionante della nostra applicazione.
%===========================================================================

%===========================================================================
\section{Problem analysis}
\labelsec{ProblemAnalysis}
Il problema definito dai requisiti si colloca nell'ambito dell'IoT, dove è diffuso l'utilizzo della cosiddetta \emph{architettura esagonale} come design pattern per gestire il rapporto tra input, elaborazione ed output nei sistemi distribuiti. Un ruolo centrale viene rivestito dalla business logic e dal modello delle risorse (\emph{Resource Model}), mentre gli altri componenti del sistema vengono visti attraverso degli adapter verso le varie tecnologie ed implementazioni.\\

Il modello delle risorse è un disaccoppiatore del mondo fisico dal mondo della logica applicativa, che deve essere indipendente dalla tecnologia. Nello specifico:
\begin{enumerate}
\item un cambiamento del sensore fisico causa un cambiamento nello stato del modello del sensore stesso
\item al cambiamento del modello, l'informazione viene notificata al controller (è un observer del modello)
\item il controller modifica quindi il modello dell'attuatore in base alla logica applicativa
\item l'aggiornamento del modello dell'attuatore comporta infine un aggiornamento dell'attuatore fisico
\end{enumerate}

Come analisti riteniamo vantaggioso introdurre un modello delle risorse così da non vincolare la logica applicativa a dettagli tecnologico-implementativi, sebbene ciò comporti un piccolo sforzo aggiuntivo iniziale. Tale overhead è però un investimento a fronte di futuri sviluppi di applicazioni simili, inoltre, se il modello fosse standardizzato, sarebbe garantita l'interoperabilità tra sistemi diversi.

\subsection{Resource Model}
Usiamo per la definizione del modello delle risorse un linguaggio dichiarativo che consenta di esprimere sia lo stato di ciascun componente, sia le operazioni primitive su di esso. A tal fine, introduciamo il seguente modello scritto in Prolog:\\

\lstinputlisting[language=Prolog, keywordstyle=\color{black}]{../it.unibo.finalTask2018/resourceModel.pl}

\subsection{Logical architecture}
%%Immagine informale. Sottoparagrafi per spiegare meglio i componenti che sono cambiamenti rispetto a prima (analisi dei requisiti) in seguito all'introduzione del modello delle risorse.

In seguito all'aggiunta del \emph{Resource Model} possiamo definire la seguente architettura logica informale del sistema:

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.4]{img/informalLogicalArchitecture.png}
\caption{Architettura logica informale}\labelfig{informalLA}
\end{figure}

Rispetto all'architettura risultante dall'analisi dei requisiti, sono stati aggiunti due componenti: \texttt{Controller} e \texttt{SoftwareAgent}. 

\subsection{Controller}
Il ruolo del \texttt{Controller} è quello di gestire il modello delle risorse in base agli eventi ricevuti dai sensori e alla logica applicativa. Ci viene naturale utilizzare il pattern MVC: Resource Model, sensori/attuatori e Controller.

Modelliamo il \texttt{Controller} come un attore in grado di ricevere informazioni di input ed emettere comandi di output.

\lstinputlisting[style=style_qa, firstline=1, lastline=113]{../it.unibo.finalTask2018/src/MVC.qa}

Il \texttt{Controller}, tramite un \emph{EventHandler}, mappa ogni evento emesso dai sensori in un evento \codescript{inputCtrlEvent  : inputEvent( CATEG, NAME, VALUE )}. In questo modo sensori fisici diversi vengono trattati allo stesso modo e gli eventi da essi inviati non vengono mai persi, essendo l'\emph{EventHandler} un componente event-driven. Il \texttt{Controller}, per discriminare la natura degli eventi, sfrutta i campi \codescript{CATEG} e \codescript{NAME} del payload dell'evento.

Ad ogni modifica del Resource Model, il \texttt{Controller} emette degli eventi \codescript{ctrlEvent : ctrlEvent( CATEG, NAME, CMD )} per notificare il cambiamento di stato ai vari attuatori.

Attualmente sono soddisfatti i requisiti \code{R-TempOk} e \code{R-TimeOk} in quanto il \texttt{Controller} blocca ogni modifica allo stato del robot al di fuori di un certo intervallo temporale o in presenza di temperature troppo elevate.

\subsection{Software Agent}
Il \texttt{SoftwareAgent} realizza la logica applicativa in collaborazione col Controller,  decidiamo quindi di modellarlo come un attore nel suo stesso contesto.

In questa fase preliminare, per motivi di testing, il \texttt{SoftwareAgent} fa ruotare il robot quando esso viene rilevato dai sonar a distanza ravvicinata.

\lstinputlisting[style=style_qa, firstline=114, firstnumber=114]{../it.unibo.finalTask2018/src/MVC.qa} 

\subsection{Changes to HumanOperator}
Rispetto al modello precendente, è stata aggiunta una \emph{GUI} utilizzabile dall'utente via web. Questa è composta da bottoni che, quando vengono premuti, scatenano eventi \codescript{usercmd : usercmd(X)}. Lo \texttt{HumanOperator} cattura questi eventi e li inoltra sotto forma di messaggi \codescript{cmd : cmd(X)} al Controller.

Per rapidità di prototipazione, abbiamo deciso di  utilizzare per la \emph{GUI} web il flag \codescript{-httpserver}, ma in futuro potrà essere sostituita da un'implementazione differente per soddisfare i requisiti \code{R-Start} e \code{R-Stop}.

\lstinputlisting[style=style_qa, lastline=25]{../it.unibo.finalTask2018/src/HumanOperatorWithGUI.qa} 

\subsection{VirtualRobotNode}
Il robot virtuale si mette in attesa di messaggi \codescript{moveRobot} e li interpreta come comandi di movimento. Tuttavia i cambiamenti nel modello del robot vengono notificati all'esterno sotto forma di eventi \codescript{ctrlEvent}.

Per effettuare la conversione da \codescript{ctrlEvent} a messaggi abbiamo utilizzato un \emph{EventHandler}. Questo permette di accodare gli eventi senza il rischio di perderne qualcuno: il robot virtuale è quindi un componente \emph{event-driven}.

\lstinputlisting[style=style_qa, lastline=13]{../it.unibo.finalTask2018/src/virtualRobotNode.qa} 

Poichè gli \emph{EventHandler} possono solo convertire eventi in messaggi con lo stesso payload, introduciamo l'attore \texttt{nodebroker}, il cui compito è quello di convertire messaggi \codescript{ctrlMsg : ctrlEvent(CATEG, NAME, CMD)} inviati dall'\emph{EventHandler} in messaggi \codescript{moveRobot : moveRobot( CMD )} per il robot virtuale.

\lstinputlisting[style=style_qa, firstline=52 , lastline=57, firstnumber=52]{../it.unibo.finalTask2018/src/virtualRobotNode.qa} 

\subsection{Changes to HueLampAgent}
Come per il robot, anche il modello della \texttt{HueLamp} dev'essere aggiornato per poter lavorare con gli eventi \codescript{ctrlEvent} emessi dal Controller. Analogamente a quanto fatto prima, abbiamo utilizzato un \emph{EventHandler} per convertire tali eventi in \codescript{blinkCmd}, ovvero nel formato degli eventi gestiti dalla lampada.\\

L'attuale implementazione è un oggetto \emph{mock} che mostra un'interfaccia grafica in grado di ''lampeggiare''.

\lstinputlisting[style=style_qa, lastline=35]{../it.unibo.finalTask2018/src/hueLampAgentGui.qa} 

% mvccontroller (racchiude il resource model) + eventHandler
% softwareagent (quali requisiti sono stati soddisfatti al momento)
% console web (-httpserver) e come funziona la catena di eventi
% virtual robot: eventHandler per accodare e non perdere gli eventi ctrlEvent essendo un componente event-driven. Questi sono inviati da...

%===========================================================================

%===========================================================================
\section{Project}
\labelsec{Project}
%===========================================================================

%===========================================================================
\section{Implementation}
\labelsec{Implementation}
%===========================================================================

%===========================================================================
\section{Testing}
\labelsec{Testing}
%===========================================================================

%===========================================================================
\section{Maintenance}
\labelsec{Maintenance}
%===========================================================================

%===========================================================================
\section{Deployment}
\labelsec{Deployment}
%===========================================================================
 
%===========================================================================
\section{Author}
\labelsec{Author}
%===========================================================================

\vskip.5cm
%%% \begin{figure}
\begin{tabular}{ | c |  }
\hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
  Photo of the author 
  \\
\hline
   %\includegraphics[scale = 0.7]{img/foto_autore.jpg}
   %\includegraphics{img/foto_autore.jpg}
  \\
\hline
\end{tabular}
 
\end{document}
